{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML ASSIGNMENT 1\n",
    "\n",
    "_**THEOREM**_ : \n",
    "\tProve that under Gaussian assumption linear regression amounts to least square.\n",
    "\n",
    "\n",
    "_**Proof**_:   \n",
    " When faced with a regression problem, why might linear regression, and\n",
    "specifically why might the least-squares cost function J, be a reasonable\n",
    "choice? In this section, we will give a set of probabilistic assumptions, under\n",
    "which least-squares regression is derived as a very natural algorithm.\n",
    "Let us assume that the target variables and the inputs are related via the\n",
    "equation \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "y^{(i)}=\\theta^{T} x^{(i)} \\ +\\ \\epsilon^{(i)}\\\n",
    "\\end{split} \n",
    "\\end{equation}\n",
    "\n",
    "where $\\epsilon^{(i)}$ is an error term that captures either unmodeled effects (such as\n",
    "if there are some features very pertinent to predicting housing price, but\n",
    "that weâ€™d left out of the regression), or random noise. Let us further assume\n",
    "that the  $\\epsilon^{(i)}$ are distributed IID (independently and identically distributed)\n",
    "according to a Gaussian distribution (also called a Normal distribution) with mean zero and some variance $\\sigma$. We can write this assumption as\n",
    "\n",
    "$$\\epsilon^{(i)}\\ \\sim \\ \\mathcal{N}(0,\\sigma^2)$$\n",
    "\n",
    "i.e., the density of $\\epsilon^{(i)}$ is given by $$p(\\epsilon^{(i)})\\ =\\ \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(\\epsilon^{i})^2}{2\\sigma^{2}}\\right)$$\n",
    "\n",
    "This implies that $$p(y^{i}|x^{i};\\theta)\\ =\\ \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(y^{(i)}-\\theta^{T} x^{(i)})^2}{2\\sigma^{2}}\\right)^{2}$$\n",
    "\n",
    "The notation $p(y^{i}|x^{i};\\theta)$  indicates that this is the distribution of $y^{(i)}$ given $x^{(i)}$ and parameterized by $\\theta$. Note that we should not condition on $\\theta$$(p(y^{i}|x^{i};\\theta))$, since $\\theta$ is not a random variable. We can also write the distribution of $y^{(i)}$ as \n",
    "\n",
    "$$y^{(i)}|x^{(i)}; \\theta\\ \\sim\\ \\mathcal{N}(\\theta^{T} x^{(i)},\\sigma^2)$$\n",
    " \n",
    " The probability of the data is given by\n",
    " $p(\\vec{y}|X;\\theta)$. This quantity is typically viewed a function of $\\vec{y}$ (and perhaps $X$),\n",
    " for a fixed value of $\\theta$. When we wish to explicitly view this as a function of\\ $\\theta$, we will instead call it the **likelihood** function :\n",
    " \n",
    " $$\\textbf{L}(\\theta)\\ =\\ \\textbf{L}(\\theta,\\textbf{X},\\vec{y})\\ = \\ p(\\vec{y}|X;\\theta)$$ \n",
    " \n",
    " $$= \\prod_{i=1}^{m}p(y^{i}|x^{i};\\theta)=\\ \\prod_{i=1}^{m}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(y^{(i)}-\\theta^{T} x^{(i)})^2}{2\\sigma^{2}}\\right)$$\n",
    " \n",
    " Instead of maximizing **L($\\theta$)** , we can also maximize any strictly increasing function of **L($\\theta$)**. In particular, the derivations will be a bit simpler if we instead maximize the **log likelihood** :\n",
    " $$\\ell(\\theta)=\\log\\textbf{L}(\\theta)=\\  \\log\\prod_{i=1}^{m}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(y^{(i)}-\\theta^{T} x^{(i)})^2}{2\\sigma^{2}}\\right)$$ $$=\\sum_{i=1}^{m}\\log \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(y^{(i)}-\\theta^{T} x^{(i)})^2}{2\\sigma^{2}}\\right)$$\n",
    "  $$=m\\log\\frac{1}{\\sqrt{2\\pi}\\sigma}-\\frac{1}{\\sigma^2}*\\frac{1}{2}\\sum_{i=1}^{m}(y^{(i)}-\\theta^{T} x^{(i)})^2$$\n",
    "  \n",
    "  Hence, maximizing  gives the same answer as minimizing $\\ell(\\theta)$ : $$\\frac{1}{2}\\sum_{i=1}^{m}(y^{(i)}-\\theta^{T} x^{(i)})^2$$\n",
    "  \n",
    "  which we recognize to be **J($\\theta$)**, our original least-squares cost function.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
